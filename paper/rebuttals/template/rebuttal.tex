\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\usepackage{enumitem}
\usepackage{pslatex}
\usepackage{color}
\usepackage{bm}
\usepackage[dvipsnames]{xcolor}
\usepackage[normalem]{ulem}
\definecolor{orange}{RGB}{230, 81, 0}
\definecolor{purple}{RGB}{170, 0, 255}
\definecolor{mygreen}{RGB}{76, 175, 80}
\usepackage{framed}
\newcommand{\vect}[1]{\boldsymbol{#1}}
\definecolor{shadecolor}{RGB}{210, 210, 210}
\usepackage{csquotes}

\usepackage{wrapfig}

\setlength{\parindent}{0em}
\setlength{\parskip}{0.5em}


\newcommand{\todo}[1]{{\leavevmode\color{orange}[TODO: #1]}}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{newtxmath}
\DeclareMathAlphabet{\mathpzc}{T1}{pzc}{m}{it}
\def\given{\mid}
\usepackage{bm}
\def\tnull{{\text{null}}}
\def\vec#1{{\vect #1}}
\def\mat#1{\mathbf{#1}}

%
% Huxtable dependencies (see R package)
\usepackage{array}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{siunitx}
\usepackage{ulem}
\usepackage{colortbl}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{calc}
\usepackage{tabularx}
\usepackage{threeparttable}
\usepackage{wrapfig}
\usepackage{adjustbox}
\usepackage{hyperref}
\usepackage{romannum}

% Allow landscape rotation on table page
\usepackage{lscape}

% abbreviations
\def\etal{\emph{et~al}.\ }
\def\eg{e.g.,~}
\def\ie{i.e.,~}
\def\cf{cf.\ }
\def\viz{viz.\ }
\def\vs{vs.\ }



\usepackage{hyperref}

\usepackage[style=nature,
					backend=biber,
					sortcites=true,
					autocite=superscript
]{biblatex}

\AtEveryBibitem{%
 \clearfield{url}%
   \clearfield{month}%
 \clearfield{issn}%
 \clearfield{doi}%%
}


\addbibresource{./main.bib}


%
% HEADER
%



\newcounter{comment}[subsection]


%
% COLORBOX
%
\usepackage{tcolorbox}
\tcbuselibrary{breakable}
\newtcolorbox[]{sectionbox}[1]{colback=white,colframe=black,colbacktitle=white!50!gray,coltitle=black,fonttitle=\bfseries,phantom=\refstepcounter{comment},title={Comment \arabic{section}.\arabic{comment}},list entry={Comment \arabic{section}.\arabic{comment}\quad}, breakable}


\DeclareUnicodeCharacter{FB01}{fi}
\usepackage{dirtytalk}

\def\figdir{../Figs}

%\usepackage[most]{tcolorbox}
\newcommand{\sada}[1]{{\leavevmode\color{orange}[SK: #1]}}
\newcommand{\add}[1]{{\leavevmode\color{blue}#1}}
\newcommand{\del}[1]{{\leavevmode\color{red}\sout{#1}}}
\newcommand{\response}[1]{{\noindent \textbf{Response:} \\ \\ \noindent #1}}
%\newcommand{\rcomment}[1]{{\bigskip\begin{snugshade}\begin{quotation}\noindent #1 \end{quotation}\end{snugshade} }}

\newcommand{\rcomment}[1]{%
\vspace{10pt}
\begin{sectionbox}
s #1
\end{sectionbox}
}

\newcommand{\correction}[2]{{\begin{quotation}\noindent {#1}{\it #2} \end{quotation} }}
%\newcommand{\correction}[2]{{\bigskip\begin{quotation}\noindent {#1}{\it #2} \end{quotation} }}

\newcommand{\mycaption}[2]{%
  \caption[#1]{\textbf{#1} \small#2}%
}
% comment out when submitting
\definecolor{myblue}{RGB}{33,150,243}
\definecolor{mygreen}{RGB}{76, 175, 80}
\definecolor{purple}{RGB}{170, 0, 255}

\makeatletter
\renewcommand{\maketitle}{\bgroup\setlength{\parindent}{0pt}
\begin{flushleft}
\Large  \textbf{\@title}
\end{flushleft}\egroup
}
\makeatother
\title{Re: Nature communication submission 23-40318}
\date{}

\newgeometry{margin=1in, top=1in}
\begin{document}
\maketitle

\bigskip
\thispagestyle{empty}
\vspace{-0.4cm}
\noindent Dear Referees,\\
\vspace{-0.25cm}

Things to emphasize in the cover letter
\begin{itemize}
\item We did not propose a new method to make clustering better. We focus on the limit performance of graph embedding 
\item Broad impact of our results.   
\item Did not explore the best parameter configuration and adopt the default commonly used parameter set, which already achieves nearly optimal performance. 
\item We added new clustering method to provide additional references for practical performances.  
\end{itemize}


\bigskip

Kind regards

\bigskip

Sadamori Kojaku, Filippo Radicchi, Yong-Yeol Ahn, and Santo Fortunato.

\pagenumbering{arabic}
\clearpage
\newgeometry{margin=1in}
\setcounter{page}{1}
\tableofcontents
\clearpage

\section{Point-by-point response}
Dear referees,

We wanted to express our gratitude for the insightful comments from the referees. We have carefully considered all of your suggestions and feedback, and we have made every effort to reflect them into the revised version. Here, we detail our changes on a point-by-point basis.

\subsection{Response to Referee 1}
\setcounter{section}{1}


\rcomment{%
This paper studied the community detectability of network embedding methods using two specific simulation case studies. After comparing various existing community detection methods, the authors found that node2vec can achieve the upper limit of optimal detectability in networks generated by stochastic block models, specifically the planted partition model (PPM) and the LFR model. Furthermore, the authors provided theoretical insights into why the eigenvectors of node2vec, as well as deepwalk and LINE, can reach this detectability limit. While the study's design is logically reasonable, I have several major concerns:}

Thank you for the valuable comments. 
In the following, we go through the review point-by-point and address the referee's concerns one by one.

\rcomment{
1. Limited Scope: The paper's focus on only two simulation studies and the use of specific hyperparameter settings (e.g., undirected, sparsity, SBM networks) raises concerns about the generalizability of the conclusions. It is uncertain how the study can demonstrate the applicability of its findings to a broader audience such as from Nature Communications.
}

\response{
Thank you for your valuable feedback. We would like to clarify that our work provides a theoretical foundation that 
bridges network science and machine learning and 
highlights the factor that gives rise to the remarkable capacity of node2vec, DeepWalk, and LINE, which are the basis methods for various graph embedding methods. The fact that these simple graph embedding methods already achieves the optimal limit implies that complex architectures such deep layers and as non-linear activations are not necessary for community detection. This finding has a broad implication in the design of graph embedding algorithms, and we believe that our finding is highly relevant to the readers of Nature Communications, especially given a recent surge of interest in graph embedding techniques based on neural networks in machine learning and network science. 

We also acknowledge the need for further validation, particularly in exploring the performance across different hyperparameter settings. To address this, we have conducted an additional experiment, which we will summarize below.
}

\rcomment{
2. Lack of Novelty: The derivation that Deepwalk and LINE share eigenvectors with node2vec is not novel, as NetMF (Ref #30) previously pointed out.
}

\response{
We acknowledge that the previous study demonstrates the equivalence to the matrix factorization, as we clarified in our manuscript (line xxx). Our main contribution is to go one step further to connect with the random matrix theory to derive the fundamental capacity of these methods for community detection. We also would like to clarify that this extension is not a straightforward, as the original form of node2vec involves element-wise logarithms that are imcompatible with random matrix theory. 
}

\rcomment{
3. Unexplored Hyperparameters: The paper does not delve into the impact of the number of walks on performance, as the implementation uses specific numbers. 
}

\response{
Thank you for your suggestion. We have incorporated new figures that investigate the influence of the number of walks on performance. Our findings indicate that the model's performance is suboptimal when the number of walks is too low, which is likely due to inadequate training of word2vec. However, as we increase the number of walks, the model's performance improves, although the rate of improvement diminishes. Eventually, the performance improvements saturate after xxx walkers per node. We confirm that the detectability limit for the best performing setting is in line with our analytical resuts. 
}
% We can create a performance profile consiting of four panels. One panel per method and a line corredpsonds to a particular number of walks. 

\rcomment{
4. Sensitivity to Outliers: Given that K-means clustering is known to be sensitive to outliers, it is crucial to discuss how robust community detection is in scenarios of low network sparsity. 
}

\response{
While we acknowledge that the limitation of the $K$-means algorithm, for our analysis, we do not think that the outliers are the major concern.
In fact, our results show that the clustering performs very well, with performance mostly comparable with the best performing methods. The excellent performance implies that the effect of outliers is negligible in our experiment. 

The robustness against outliers is probably because we classify the nodes based on cosine similarity. Because the cosine distance is strictly bounded between 0 and 2, the clustering is robust even if few nodes are very far from the rest of the nodes. 

To clarify this point, we modified the manuscript as follows,
}

....


\rcomment{
5. Hyperparameter Tuning: To ensure fair benchmarking, the authors should provide a rationale for their choice of hyperparameters, such as the decision to discard the largest eigenvector when using modularity. Additionally, hyperparameter tuning for other methods should be conducted and justified.
}

\response{
We would like to clarify that we did not discard the principal eigenvector of the modularity matrix. However, we do discard the principal eigenvector of the adjacency matrix when computing the modularity embedding. Specifically, the $k$th principal eigenvector of the modularity matrix corresponds to the $(k+1)$th eigenvector of the adjacency matrix, as we highlighted in the  SI. Therefore, in order to compute the modularity embedding, the principal eigenvector of the adjacency matrix should be discarded. Additionally, it is worth noting that the principal eigenvector of the adjacency matrix is parallel to the degree sequence, as described in the SI. Since the degree sequence is independent of the community structure in the SBMs, the principal eigenvector of the adjacency matrix does not improve the detectability limit.

As for other hyperparameters, such as the window lengths, we tested them using commonly used parameter sets from the original paper and the default values of widely used implementations. Considering the widespread use of these hyperparameters and their nearly optimal performance, we do not believe that our selection of the hyperparameter set is biased. However, we do acknowledge that the additional experiments suggested by the referee provide further numerical evidence that our results are robust against the choice of hyperparameters.
}


\rcomment{
6. Numerical Instability: The paper should explain how small eigenvalues were processed to prevent numerical instability. 
}

The comment is not clear to me. The solver converges with a sufficient accuracy. 

\rcomment{
7. Dimensionality Exploration: While the authors investigated two different low-dimensional representations (C=16, 64), a more extensive exploration across various dimensions would enhance the experiment's rigor. This would provide a more comprehensive understanding of how dimensionality impacts performance.
}


\response{
We appreciate the referee's valuable suggestion. We added a new figure exploring the effect of dimenentionality. We find that the neural graph embeddings methods are surprisingly robust against the choice of the dimensions, as long as the dimension is high to some degree. 
}

\clearpage

\subsection{Response to Referee 2}


\rcomment{%
The authors have derived limits for when some graph embedding methods based on shallow neural networks without non-linear activation can detect planted communities in networks. Their findings indicate that the embedding methods perform near-optimal when provided specific information about the planted structure while clustering the embedded nodes. This result suggests that the embedding quality is robust and that the subpar performance reported in previous work stems from shortcomings in the clustering step. 

The results provide insights into how neural embeddings fail with community detection, but the presented work only supports some claims and conclusions. Considering the following comments will help the authors improve their manuscript.
}

Thank you for the valuable feedback on our manuscript. We have considered the  points raised and have made the following revisions.

\rcomment{

MAJOR REVISIONS 

Multiple times, the manuscript states that how and why neural embeddings work for community detection remains unknown. However, the manuscript never addresses this research gap. Instead, it focuses on a narrower gap – how shallow neural embedding methods perform on sparse networks – creating a mismatch between the research gap and contribution. Neither does "Our results provide an alternative perspective to the common design principles of neural networks widely accepted for text and image processing" describe the contribution. All claims must be supported. 
}

\response{
We appreciate the reviewer's feedback and acknowledge our focus is on specific sets of graph neural embeddings. However, we would like to clarify a few points to highlight that our results are a major step forward toward the research question.
\begin{enumerate}
\item 
Our results demonstrate an equivalence between the embedding learned by node2vec and the eigenvectors of the normalized Laplacian matrix, under some reasonable conditions. 
These results allow us to leverage the existing knowledge of the normalized Laplacian matrix to gain insights into the process by which node2vec generates an embedding, specifically in relation to how communities are embedded. 
Specifically, with the eigenvectors of the normalized Laplacian matrix capture communities in ways that can be linearly separable and hence detectable by the $K$-means algorithm~\cite{vonluxburgTutorialSpectralClustering2007}. 

\item 
We carefully selected the fundamental graph embeddings that encompass the core elements of numerous graph embedding techniques, to gain valuable insights that can be applicable to a wide spectrum of graph embeddings.
For example, many graph embeddings are a direct application of node2vec or DeepWalk, with additional preprocessing of network data and/or constraints on the random walks to fine-tune the embeddings~\cite{Khajehnejad2021-qh,Perozzi2017-gk,dong2017metapath2vec,Peng2021-uj,Kojaku2021a,Murray2020UnsupervisedEO}.
node2vec corresponds to a special case of more complex graph neural networks with deeper neural architectures and non-linear activation~\cite{hamiltonInductiveRepresentationLearning2017,Zhang2019AttributedNE}.
Our results demonstrate that even the basic version of node2vec, without the deep architecture, non-linear activations, preprocessing of network data, and tuning of walks, already achieves the theoretical limit of community detectability. This finding is highly relevant to many graph embedding methods that share core components with node2vec.
\end{enumerate}
In order to emphasize this point, we modified the manuscript as follows...
}

\rcomment{
Considering the caveats discussed at the end of the manuscript, the actual contribution lies in providing evidence that node2vec and other shallow neural embeddings perform near optimal if provided extra information in the critical clustering step. This theoretical result is of limited practical value since such information is unavailable in applications with real-world data. Therefore, the unfair comparisons with methods using no or less extra information are misleading. Comparing the performance of neural embeddings with and without extra information in the clustering step better aligns with the manuscript's claim. 
}

\response{
We appreciate the reviewers for pointing this out. We also agree that the practical value is of great importance and would like to highlight how our results provide the practical value.

First, we would like to clarify that all methods tested in our numerical simulations utilized the additional information about the planted communities. For example, all methods are given extra information about the number of communities. Belief Propagation, in particular, additionally has the information about the size of the communities and the number of edges within and between them. We compare the performance of the methods with a fair access to the extra information and did not favor the graph embedding methods specifically.

Second, the practical effectiveness of neural graph embedding for community detection has been tested in a previous study~\cite{tandonCommunityDetectionNetworks2021}. The results of the study demonstrated that node2vec combined with the $K$-means algorithm performed comparably or even worse than widespread community detection methods. We also reported the performance of the $K$-means algorithm in the Supplementary Information of our manuscript, confirming the previous study. However, it had been unclear whether the cause of the underperformance was due to the clustering algorithm or the graph embedding.
Our work demonstrate that the performance of graph nerual network mostly matches with the optimal community detection method when the performance of the clustering step is maximized, providing clarification that it is the clustering step that accounts for the underperformance. 

Our results, together with the results of the previous study, provided a key practical implication.  
The graph neural embeddings are optimal in terms of the detectability limit. This means that if the embedding is utilized to encode information about community structure as part of feature vectors for downstream applications  which do not necessitate clustering steps (e.g., link prediction and node classification), our results guarantee that the community information will be accurately represented in the feature vector.
However, if the goal is to extract clusters from the embeddings, there is still a substantial room for improvement due to lack of the information about the communities, including the number of communities. This challenge is not specific to clustering graph embeddings, but rather a general problem in clustering any type of data.

Nevertheless, we believe that providing the practical performance without the additional information, including the number of communities, would provide further support. Therefore, we employed another clustering method, xxxx, which can automatically determine the number of communities from the data.
}

\rcomment{
MINOR REVISIONS 

The main manuscript dumps the detectability limits for node2vec in the results section without sufficient context, and the methods section would be easier to follow with better-motivated assumptions. 
}

\rcomment{
Why does belief propagation underperform in the simplest cases with high link density and low mixing? The explanation that the algorithm struggles with many local minima requires more convincing arguments. Challenging cases often have more local minima than simple cases. 
}

\response{
The optimality of the belief propagation hinges on the premise that the network has no loop. This assumption holds mostly true for sparse networks with a homogeneous degree distribution but is violated when the network is dense. 
And, even if the network is sparse, many loops are likely to be formed if  
 the degree distribution is heterogeneous ~\cite{Bianconi2005LoopsOA,Cantwell2023}.
As a results, the belief propagation tends to find a poor local optimum instead of the global one, especially for the LFR network, where the degree distribution is heterogeneous.
}

\rcomment{
Figure 1 suggests that non-backtracking and node2vec have similar performance. The claim in the caption that node2vec outperforms spectral methods seems unsupported. 
}

\response{
We appreciate the through read by the referee. We corrected the caption as follows:

\begin{displayquote}
\color{blue}
node2vec performs comparably with the non-backtracking method and outperforms other spectral embedding method ... 
\end{displayquote}
}


\rcomment{
In summary, the authors can improve their manuscript by deciding whether to focus on theory or real-world applications. If it is theory, the manuscript must match its claims and results, highlighting that the reported substandard performance of node2vec for community detection stems from the k-means clustering. If it is real-world applications, they should improve the clustering step without extra information available. Ultimately, the embedding clustering problem must be simpler than the community detection problem in the first place to achieve overall better performance.
}

\response{
We appreciate the constructive comments by the referee and provided the opportunities to improve our manuscript.  
Our emphasis is on the fundamental limit of graph neural embeddings, and our results demonstrated that the detectability limit for graph neural embedding sharply separated the detectable and undetectable regimes, which are the results providing the clear evidence of our claim. Additionally, our results provide critical implications for real-world applications of graph embedding, as we clarified in our previous response. 
Therefore, we believe that our work will make a valuable contribution to the theoretical understanding as well as further developments of practical graph embedding methods for community detection.  
}


\clearpage
\printbibliography{}
\end{document}
\section{New figures and tables:}
